{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a33d70a",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "Split train dataset into train, val, and test. Export a dataset from CVAT can't split automatically from tasks. So, we need to split manually if we don't specify the subsets. This notebook do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b88a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import yaml\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade6a33",
   "metadata": {},
   "source": [
    "Specify train, val, and test composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec198816",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 70\n",
    "n_val = 20\n",
    "n_test = 10\n",
    "\n",
    "if sum([n_train, n_val, n_test]) != 100:\n",
    "    raise ValueError(\"Total composition must be 100!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f47ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_dataset = \"C:/Users/eats/projects/IASS/asset/task_20250507-epsilon-skip_1_dataset_2025_05_19_03_18_32_ultralytics yolo detection 1.0\"\n",
    "dir_output = f\"{dir_dataset}/data-split\"\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "os.makedirs(f\"{dir_output}/images/train\", exist_ok=True)\n",
    "os.makedirs(f\"{dir_output}/images/val\", exist_ok=True)\n",
    "os.makedirs(f\"{dir_output}/images/test\", exist_ok=True)\n",
    "os.makedirs(f\"{dir_output}/labels/train\", exist_ok=True)\n",
    "os.makedirs(f\"{dir_output}/labels/val\", exist_ok=True)\n",
    "os.makedirs(f\"{dir_output}/labels/test\", exist_ok=True)\n",
    "\n",
    "with open(f\"{dir_dataset}/data/data.yaml\", \"r\") as file:\n",
    "    data_yaml = yaml.safe_load(file)\n",
    "\n",
    "with open(f\"{dir_dataset}/data/train.txt\", \"r\") as file:\n",
    "    paths_train = file.read()\n",
    "    paths_train = [item for item in paths_train.split(\"\\n\") if item]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ed80f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': {0: 'bicycle',\n",
       "  1: 'motorbike',\n",
       "  2: 'car',\n",
       "  3: 'truck',\n",
       "  4: 'bus',\n",
       "  5: 'person'},\n",
       " 'path': '.',\n",
       " 'train': 'train.txt'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d71173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/images/train/epsilon_0.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff9c56a",
   "metadata": {},
   "source": [
    "Function to split dataset into train, val, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c7aa6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1, seed=None):\n",
    "    if not abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6:\n",
    "        raise ValueError(\"Ratios must sum to 1.0\")\n",
    "    \n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    data = data.copy()\n",
    "    random.shuffle(data)\n",
    "\n",
    "    total = len(data)\n",
    "    train_end = int(train_ratio * total)\n",
    "    val_end = train_end + int(val_ratio * total)\n",
    "\n",
    "    train = data[:train_end]\n",
    "    val = data[train_end:val_end]\n",
    "    test = data[val_end:]\n",
    "\n",
    "    return train, val, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "924d3352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 300, 150)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train, split_val, split_test = split_dataset(paths_train)\n",
    "\n",
    "len(split_train), len(split_val), len(split_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd525a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/images/train/epsilon_955.jpg',\n",
       " 'data/images/train/epsilon_220.jpg',\n",
       " 'data/images/train/epsilon_653.jpg')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_train[0], split_val[0], split_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e9ca504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Split Images [train]: 100%|██████████| 1050/1050 [00:03<00:00, 328.56it/s]\n",
      "Split Images [val]: 100%|██████████| 300/300 [00:00<00:00, 343.35it/s]\n",
      "Split Images [test]: 100%|██████████| 150/150 [00:00<00:00, 376.79it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    \"train\": split_train,\n",
    "    \"val\": split_val,\n",
    "    \"test\": split_test,\n",
    "}\n",
    "\n",
    "# copy the split data to output directory\n",
    "for name, list_path in dataset.items():\n",
    "    for path in tqdm(list_path, desc=f\"Split Images [{name}]\"):\n",
    "        path_src_img = f\"{dir_dataset}/{path}\"\n",
    "        path_dst_img = path_src_img.replace(\"/data/\", \"/data-split/\").replace(\"/train/\", f\"/{name}/\")\n",
    "        \n",
    "        path_src_label = path_src_img.replace(\"/images/\", \"/labels/\").replace(\".jpg\", \".txt\")\n",
    "        path_dst_label = path_dst_img.replace(\"/images/\", \"/labels/\").replace(\".jpg\", \".txt\")\n",
    "        \n",
    "        shutil.copyfile(path_src_img, path_dst_img)\n",
    "        if os.path.exists(path_src_label):\n",
    "            shutil.copyfile(path_src_label, path_dst_label)\n",
    "\n",
    "# create txt file related to the split data\n",
    "name = \"train\"\n",
    "with open(f\"{dir_output}/{name}.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join([item.replace(\"train\", name) for item in split_train]))\n",
    "\n",
    "name = \"val\"\n",
    "with open(f\"{dir_output}/{name}.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join([item.replace(\"train\", name) for item in split_val]))\n",
    "\n",
    "name = \"test\"\n",
    "with open(f\"{dir_output}/{name}.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join([item.replace(\"train\", name) for item in split_test]))\n",
    "\n",
    "# create yaml file related to the split date\n",
    "data_yaml[\"val\"] = \"val.txt\"\n",
    "data_yaml[\"test\"] = \"test.txt\"\n",
    "with io.open(f\"{dir_output}/data.yaml\", 'w', encoding='utf8') as file:\n",
    "    yaml.dump(data_yaml, file, default_flow_style=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2963b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/eats/projects/IASS/asset/task_20250507-epsilon-skip_1_dataset_2025_05_19_03_18_32_ultralytics yolo detection 1.0/data/images/train/epsilon_610.jpg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_src_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46916715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/eats/projects/IASS/asset/task_20250507-epsilon-skip_1_dataset_2025_05_19_03_18_32_ultralytics yolo detection 1.0/data-split/images/test/epsilon_610.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dst_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d72d5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': {0: 'bicycle',\n",
       "  1: 'motorbike',\n",
       "  2: 'car',\n",
       "  3: 'truck',\n",
       "  4: 'bus',\n",
       "  5: 'person'},\n",
       " 'path': '.',\n",
       " 'train': 'train.txt',\n",
       " 'val': 'val.txt',\n",
       " 'test': 'test.txt'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698dad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
